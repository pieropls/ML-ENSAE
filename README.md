# **ðŸ¦¾Theoretical Foundations of Machine Learning**

## **ðŸ“Œ Overview**
This repository contains **tutorials and exercises** from the course *Theoretical Foundations of Machine Learning* at **ENSAE Paris**. It explores both theoretical and practical aspects of **modern machine learning**, including:
- **Regression and Overfitting** â€“ Understanding the balance between model complexity and generalization.
- **Model Selection & Penalization** â€“ Techniques to improve predictive performance while avoiding overfitting.
- **Empirical Risk Minimization (ERM)** â€“ A fundamental principle in statistical learning theory.
- **Decision Trees & Neural Networks** â€“ Core methods in supervised learning.
- **Reinforcement Learning & Deep RL** â€“ Learning from interaction in dynamic environments.
- **Unsupervised Learning** â€“ Clustering methods such as PCA and their applications.

## **âš¡ Content**
[`A One-Dimensional Regression Problem`](1.1.A.one-dimensional.regression.problem.ipynb)
This exercise introduces regression techniques in a **one-dimensional setting**, covering:
- **Linear regression** and its limitations in capturing complex patterns (polynomial function).
- **Polynomial regression** and its tendency toward **overfitting** for high-degree polynomials.
- **LASSO regularization**, demonstrating how it controls complexity by shrinking coefficients.

## **ðŸŽ“ Credits**
The course material is based on work by **Professor Vianney Perchet** â€“ [Website](https://vianney.ai/).
